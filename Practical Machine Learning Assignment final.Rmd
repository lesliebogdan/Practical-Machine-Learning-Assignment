---
title: "Practical Machine Learning: Assignment"
author: "Leslie Bogdan"
date: "5 February 2018"
output: html_document
---
<h2>  Data source and Back ground </h2>

<h3> Background </h3>

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

<h3> Data </h3>

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. 

<h3> Aim </h3>
<p> Generate a prediction model (with reference to the supplied training data sets) which will then be used to predict on a new (unknown) data set (will then be quized on the models performance).</p>

<h3> Libraries used </h3>

<li> library(ggplot2) </li>
<li> library(caret) </li>
<li> library(rpart) </li>
<li> library(rpart.plot) </li>
<li> library(rattle) </li>
<li> library(randomForest) </li>
<li> library(corrplot) </li>


<h2> Loading the Data </h2>

<p> Download the two data sets (training and testing) csv files </p>
<p> load them into dataframes </p>

```{r setup, echo = FALSE, include = FALSE}
library(ggplot2)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
```

<p> We have been asked to set.seed = '12345' </p>

```{r seed cars}
set.seed(12345)
```

<p> Make sure you are pointing at the correct working directory which contains the csv files needed (as outlined in the datasets section above) </p>

```{r load_data, echo=TRUE, cache=TRUE}

testing<-read.csv("pml-testing.csv", header=TRUE, sep=",")
training<-read.csv("pml-training.csv", header=TRUE, sep=",")
```

<h2> Cross Validation </h2>

<p> Create the training and test sets (from the training dataframe) to be used against future prediction approaches. </p>

```{r create_sets, echo=TRUE, cache=TRUE}


train_partition  <- createDataPartition(training$classe, p=0.7, list=FALSE)
train_set <- training[train_partition, ]
test_set  <- training[-train_partition, ]

```

<h2> Data Cleaning up </h2>

<p> Looking at the current state of both the 'original_train' there are many variables which seem to have many values which are close to zero.  We will now go and clean these up. </p>

<p> The dataset also seems to have allot of varibales which have allot of missing values, we also clean them up in this step. </p>

<p> Finally, we remove the variables which are related to the identification of subjects. </p>

```{r cleaning, echo=TRUE, cache=TRUE}


# Variables where majority of values are near 0 removed

near_zero_value <- nearZeroVar(train_set)
train_set <- train_set[, -near_zero_value]
test_set  <- test_set[, -near_zero_value]

# Variables where majority are NA values removed

NA_remove    <- sapply(train_set, function(x) mean(is.na(x))) > 0.9
train_set <- train_set[, NA_remove==FALSE]
test_set  <- test_set[, NA_remove==FALSE]


# Identifier columns to be removed

train_set <- train_set[, -(1:5)]
test_set  <- test_set[, -(1:5)]

```

<h2> Prediction Model Generation </h2>

<p> We will now use the following two approaches to generate prediction models within the training partition portion of the training data.  </p>

<li> Random Forest </li>
<li> Decision Trees </li>


<p> Based on the above prediction model performance against the test partition portion of the training data set (based on the  'Accuracy' measure (highest is better)), we will then apply the selected model to predict the quiz test cases . </p>



```{r prediction_models, echo=TRUE, cache=TRUE}

# Random Forest Approach

control_rf <- trainControl(method="cv", number=3, verboseIter=FALSE)
model_rf <- train(classe ~ ., data=train_set, method="rf",
                          trControl=control_rf)
model_rf$finalModel

        # Decision Trees Approach

model_dt <- rpart(classe ~ ., data=train_set, method="class")


```

<h2> Prediction Model Application and Evaluation </h2>

<p> Apply them to the Test portion of the training data set we partioned earlier. </p>


```{r apply_to_test, echo=TRUE, cache=TRUE}

# Apply Random Forest Approach

pred_rf <- predict(model_rf, newdata=test_set)
conf_model_rf <- confusionMatrix(pred_rf, test_set$classe)
conf_model_rf

rf <- conf_model_rf$overall['Accuracy']
rf_out<-1-rf

# Apply the Decision Tree Approach

pred_dt <- predict(model_dt, newdata=test_set, type="class")
conf_model_dt <- confusionMatrix(pred_dt, test_set$classe)
conf_model_dt

dt<-conf_model_dt$overall['Accuracy']
dt_out<-1-dt


```

<h2> Results </h2>

<p>  In examining the 'Accuracy' measure produced from both prediction models, we get the following </p>
  
  <li> Random Forest @  `r rf`</li>
<li> Decision Trees @ `r dt`</li>

<p> Based on the accuracy results, we select the 'Random Forest' model. </p>

<h3> Out of sample errors </h3>
 <p> The Random Forest approach had an 'out of sample error rate'Accuracy' value of `r rf` and out of sample error of `r rf_out`, while the decision tree approach had a 'Accuracy' value of `r dt` and out of sample error rate of `r dt_out`.
 
 <p> Hence, the random forest approach has been selected to be used on the test data set due it having the higher accuracy value. </p>

<h2> Application to the Test (Quiz) set </h2>

<p> We now use our selected model to predict across the 'testing' (quiz) data set. </p>

<p> head on first 20 records of the predictions produced (needed for the quiz). </p>


```{r results_output, echo=TRUE, cache=TRUE}

pred_final <- predict(model_rf, newdata=testing)
head(pred_final,20)

```
